{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Approval Prediction Analysis\n",
    "\n",
    "This project was done as an online coding challenge provided by Analytics Vidhya. The scoring method of this coding challenge is the percentage of loan approvals that have been predicted correctly. \n",
    "\n",
    "In this project my goal is to predict whether a loan will be approved or not based on a provided training and testing data set. The outcome of the decision will either be a \"Y\" which means that a loan will be approved or a \"N\" which means that the loan will not be approved. Hence, I will be developing a model that will analyse the features of each unique loan and determine if it will be approved or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set\n",
    "\n",
    "In this project, there are 13 columns of features and 614 rows of records in the training set and 12 columns of features and 367 rows of records in the test set. The one column not present in the test data set is the Loan_Status column which is only used in the training data set to see which loans would be approved. The data set variables can be seen below:\n",
    "\n",
    "<img src = \"Dataset-v.png\" style = \"width:500px;height:300px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "In order to perform the data analysis and determine which loans to approve, I will use Python 3 and the pandas, matplotlib, and numpy libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in both the training and testing data sets.\n",
    "train_set = pd.read_csv(\"train_loan.csv\")\n",
    "test_set = pd.read_csv(\"test_loan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 13), (367, 12))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seeing the relative sizes of both datasets\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, there might be missing values. Hence, we have to perform data munging in order to make the data suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values.\n",
    "train_set.apply(lambda x: sum(x.isnull()),axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is missing data in Gender, Married, Dependents, Self_Employed, LoanAmount, Loan_Amount_Term, and Credit_History. In order to rectify this, I will use imputation. \n",
    "\n",
    "For numerical values like \"Loan_Amount_Term\", I will use the median to fill in the missing values.\n",
    "\n",
    "For string or categorical values like \"Gender\", I will use mode to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values\n",
    "train_set['LoanAmount'].fillna(train_set['LoanAmount'].mode()[0], inplace=True)\n",
    "train_set['Loan_Amount_Term'].fillna(train_set['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "train_set['Gender'].fillna(train_set['Gender'].mode()[0], inplace=True)\n",
    "train_set['Married'].fillna(train_set['Married'].mode()[0], inplace=True)\n",
    "train_set['Dependents'].fillna(train_set['Dependents'].mode()[0], inplace=True)\n",
    "train_set['Self_Employed'].fillna(train_set['Self_Employed'].mode()[0], inplace=True)\n",
    "train_set['Credit_History'].fillna(train_set['Credit_History'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values again.\n",
    "train_set.apply(lambda x: sum(x.isnull()),axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results above, all the missing values have been replaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to replicate the same process for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               11\n",
       "Married               0\n",
       "Dependents           10\n",
       "Education             0\n",
       "Self_Employed        23\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            5\n",
       "Loan_Amount_Term      6\n",
       "Credit_History       29\n",
       "Property_Area         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values in test dataset.\n",
    "test_set.apply(lambda x: sum(x.isnull()),axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing missing values with mode and median found in training dataset.\n",
    "test_set['Gender'].fillna(train_set['Gender'].mode()[0], inplace=True)\n",
    "test_set['Dependents'].fillna(train_set['Dependents'].mode()[0], inplace=True)\n",
    "test_set['Self_Employed'].fillna(train_set['Self_Employed'].mode()[0], inplace=True)\n",
    "test_set['Credit_History'].fillna(train_set['Credit_History'].mode()[0], inplace=True)\n",
    "test_set['Loan_Amount_Term'].fillna(train_set['Loan_Amount_Term'].mode()[0], inplace=True)\n",
    "test_set['LoanAmount'].fillna(train_set['LoanAmount'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for missing values again in test dataset.\n",
    "test_set.apply(lambda x: sum(x.isnull()), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling in the missing data value fields, we now have to deal with possible outlier values. In order to find outlier values I will perform univariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now both the training and test data set have had their missing data values filled, we can start building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building our model we want to understand which values will help determine whether the loan will be approved or not.\n",
    "\n",
    "We want to consider:\n",
    "\n",
    "    1) Applicants who do have a credit history.\n",
    "    \n",
    "    2) Applicants with higher Applicant and Coapplicant Incomes.\n",
    "    \n",
    "    3) Applicants that have a higher education level.\n",
    "    \n",
    "    4) The property area and if it is an urban area or not.\n",
    "    \n",
    "I will be using a logistical regression model for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first drop the Loan_ID variable as it does not affect the outcome of the model at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop('Loan_ID', axis=1)\n",
    "test_set = test_set.drop('Loan_ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn requires the target variable in a separate dataset. So, we will drop our target variable from the train dataset and save it in another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"Loan_Status\" and assign it to target variable\n",
    "x = train_set.drop('Loan_Status', 1)\n",
    "y = train_set.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x)\n",
    "train_set = pd.get_dummies(train_set)\n",
    "test_set = pd.get_dummies(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the model on training dataset and make predictions for the test dataset. We can train the model on this train part and using that make predictions for the validation part. In this way we can validate our predictions as we have the true predictions for the validation part.\n",
    "\n",
    "We will use the train_test_split function from sklearn to divide our train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the accuracy of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaelcoseteng/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8324324324324325"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "pred_cv = model.predict(x_cv)\n",
    "accuracy_score(y_cv, pred_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have received accuracy of about above 83%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
